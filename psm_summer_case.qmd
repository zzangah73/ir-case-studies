---
title: "Program Evaluation with PSM--Summer Course Case"
author: "Jemma Kwon, Ph.D."
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
  docx: default
execute:
  echo: true
  warning: false
  message: false
  cache: true
freeze: auto
---

## 1. Overview

#### **Evaluation Question**

This study examines whether participation in a one-unit summer course improves short-term student retention among new entrants. The course, offered prior to the Fall 2024 semester, is designed to help incoming students—both first-time freshmen and transfers—acclimate to the university’s academic expectations, strengthen their study habits, and build early connections to campus resources. Understanding the impact of this type of early intervention is essential for assessing its effectiveness in supporting the transition to college life and promoting persistence into the next semester.

The central evaluation question is: ***Does completing a one-unit summer course prior to Fall 2024 increase the likelihood that new entrants will re-enroll in Spring 2025?*** The outcome measure, one-semester retention, captures whether students remain continuously enrolled through the following term. By focusing on this early indicator of success, the analysis seeks to determine whether structured pre-term engagement can meaningfully improve retention outcomes during the critical first year of college enrollment.

#### **Population**

The study population consists of **all degree-seeking undergraduate students in the Fall 2024 entry cohort**, including both first-time freshmen (FTF) and undergraduate transfers (UGT) who were eligible for enrollment in Spring 2025. This inclusive population represents the university’s newest entrants—the group most affected by early academic and social adjustment challenges.

Focusing on new entrants is intentional. The first year of college is widely recognized as a decisive period for establishing persistence patterns. Many students who leave the institution do so within their first two semesters, often due to difficulties adjusting to academic rigor or integrating into campus life. In contrast, students who successfully persist to the second term demonstrate a markedly higher probability of long-term retention and degree completion. By analyzing the Fall 2024 entry cohort, the study isolates the point at which early academic interventions, such as the summer course, can have the strongest and most immediate influence on student persistence.

This population definition ensures both conceptual clarity and policy relevance: **it targets the students for whom early engagement is most consequential and for whom small improvements in retention can translate into significant institutional and personal outcomes.**

#### **Treatment**

The treatment of interest is **participation in the one-unit summer course offered prior to Fall 2024**. This course serves as an early intervention intended to strengthen academic readiness and foster a sense of belonging before students begin their first regular semester.

-   `group = 1`: treated (took the course)
-   `group = 0`: comparison (did not take the course) but share similar demographic and academic characteristics

#### **Outcomes and Covariates**

The outcome variable for this analysis is **Spring 2025 retention**, defined as whether a student continued enrollment in the semester immediately following Fall 2024. This binary outcome reflects a key measure of short-term persistence among new entrants, capturing whether students remained enrolled after their first regular term at the university.

Retention status is derived from official enrollment records as follows:

-   **Continuing:** Student has an active record for **Spring 2025 (term code 20252)**.
-   **Not Enrolled:** No corresponding record found for Spring 2025.

This operationalization provides a clear, verifiable indicator of persistence based on institutional data systems.

[***Sensitivity Note***]{.underline} Blank records were reviewed to confirm that the absence of a Spring 2025 term entry accurately represents **non-enrollment** rather than delayed data entry or alternative registration activity. This verification ensures the reliability of the retention measure and strengthens the internal validity of the analysis.

[***Primary Estimand***]{.underline} **ATT (Average Treatment Effect on the Treated),** the causal effect of the course among students who took it.

#### **Design Overview**

-   **Propensity score matching (PSM)** to construct a comparison group comparable to treated students on background covariates.

-   **Exact matching** on structural factors (admit cohort, enroll load, student level, sex) to “lock” strata.

-   **Nearest-neighbor 1:1** matching within strata (no replacement), using a **logit** PS of:

    \begin{aligned}
    &\text{admit\_cohort} + \text{enroll\_load} + \text{student\_level} + \text{sex} + \text{age\_band} \\
    &+ \text{math\_placement\_level} + \text{writing\_placement\_level} + \text{eop\_status} + \text{race\_ethnicity} \\
    &+ \text{pell\_eligible} + \text{parent\_education} + \text{residency\_status}
    \end{aligned}

-   **Post-match diagnostics:** standardized mean differences (SMD) and difference in the initial standing

-   **Statistical Test: paired**

    -   **Further Diagnostic:**
        -   Continuous/approximately continuous (e.g., baseline GPA): Wilcoxon signed-rank.
        -   paired t-test as a sensitivity check if normality is plausible.
        -   Binary covariates: McNemar’s test (diagnostic for marginal homogeneity).
    -   **Binary Outcome Effect Test:**
        -   McNemar’s test (exact) with paired risk difference (b−c)/N(b−c)/N(b−c)/N and conditional OR b/cb/cb/c.
        -   If initial_standing (from HS/transfer GPA) or any covariate shows residual imbalance, fit a conditional logistic regression (stratified by matched pair).

#### **Data Source and Handling**

-   Institutional data mart extracts (no direct sharing of identifiable data);
-   Variable names pseudonymized; string fields normalized; factor levels set explicitly.
-   **Initial standing** built from high school GPA (FTF) or transfer GPA (UGT), with `0 → NA` and sensible fallback for missing transfer GPA.

#### **Scope & Limitations**

-   **Ceiling effect**: second-semester retention is high, yielding few discordant pairs and limited power for McNemar.
-   Matching is **order/tie-dependent**; results can vary slightly across control draws

#### **Planned Extensions**

*not primary for this workshop.*

-   Consider **one-year retention** as a more discriminating outcome.
-   Explore **1:2 matching** with conditional logistic regression, or more stable designs (optimal/full matching).
-   Conduct simple **sensitivity analyses** across alternative control draws to assess robustness.

------------------------------------------------------------------------

## 2. ETL via SQL

Below we \*\*show\*\* the SQL used to build the pool and spring retention slices.

``` sql
-- Pool (Fall 2024) + Retention (Spring 2025)
-- One row per student_id

WITH pool AS (
  SELECT 
      student_id, admit_cohort, enroll_load, student_level,
      sex, gender_identity, age_band, math_placement_level,
      writing_placement_level, eop_status, race_ethnicity,
      pell_eligible, parent_education, residency_status,
      hs_gpa, transfer_gpa
  FROM enrollment_table
  WHERE year_term = '20244'
    AND admit_cohort IN ('1.FTF', '2.UGT') --freshmen/transfers
),
retention AS (
  SELECT
      student_id,
      year_term,
      enrollment_status,
      attempted_units
  FROM enrollment_table
  WHERE year_term = '20252'
    AND student_level != '5'   -- exclude post-bacc/graduate
)
SELECT
    p.*,
    r.year_term          AS spring25_term_code,
    r.enrollment_status  AS spring25_status,
    r.attempted_units    AS spring25_attempted_units
FROM pool p
LEFT JOIN retention r
  ON p.student_id = r.student_id;
```

------------------------------------------------------------------------

## 3. Constructing the Analytic Sample

Now, we have two data sets: the course roster with student_id from the academic unit (n = 221) and the pool data for first time freshmen and transfer incoming students as the Fall of 2024 cohort.

In this section we merge the AU110 roster (treated = 1) with the Fall 2024 pool (controls = 0), harmonize IDs, and produce an analysis-ready data frame for PSM.

``` r
# Demo-only: showing a Windows-style path and workflow
setwd("C:/Users/FAKE/Desktop/Projects/Summer")
cohort <- read.csv("cohort_fall24.csv")
summer <- read.csv("summer_roster.csv")

library(dplyr)
library(readr)
library(stringr)

# Mark treated (in summer roster)
treated_ids <- summer$student_id

# Attach group on cohort base
cohort_flagged <- cohort %>%
  mutate(group = if_else(student_id %in% treated_ids, 1L, 0L))

# Find summer-only ids (not in cohort at census) for audit
summer_only <- anti_join(summer, cohort, by = "student_id") %>%
  transmute(student_id, group = 2L)

final_data <- bind_rows(cohort_flagged, summer_only)

# Sanity checks
stopifnot(!any(is.na(final_data$student_id)))
final_data %>% count(group, name = "n_by_group")
```

```         
  group n_by_group
1     0       4436
2     1        220
3     2          1
```

``` r
# Drop summer-only if verified not enrolled in Fall
final_data <- final_data %>% filter(group != 2L)

# Assert counts you expect (edit numbers as needed)
stopifnot(sum(final_data$group == 1L) == 220)

write_csv(final_data, "psm_final_data.csv")
head(final_data)
```

```         
student_id admit_cohort enroll_load student_level sex gender_identity age_band
1  9-------        2.UGT   Part-time             3   F              11 35-59   
2  9-------        2.UGT   Full-time             3   M              10 35-59   
3  9-------        2.UGT   Full-time             3   M              10 35-59   
4  9-------        2.UGT   Full-time             3   M              16 35-59   
5  9-------        2.UGT   Full-time             3   M              10 30-34   
6  9-------        2.UGT   Part-time             4   F              11 30-34   
  math_placement_level writing_placement_level eop_status race_ethnicity pell_eligible
1                 I                       I             N       7White   Not Eligible 
2                 I                       I             N       2Black   Pell Eligible
3                 I                       I             N       3Asian   Pell Eligible
4                 I                       I             N       9Unknown Pell Eligible
5                 I                       I             N       8TwoMore Pell Eligible
6                 I                       I             Y       6Ltnx    Pell Eligible
   parent_education        residency_status hs_gpa transfer_gpa spring25_term_code
1 CollegeExperience a.Bay Area (6 counties)      0          221              20252
2 CollegeExperience a.Bay Area (6 counties)    258          307              20252
3 Unknown           a.Bay Area (6 counties)      0          280              20252
4 CollegeExperience a.Bay Area (6 counties)      0          346              20252
5 CollegeExperience a.Bay Area (6 counties)      0          320              20252
6 First Generation  a.Bay Area (6 counties)      0          341              20252
  spring25_status spring25_attempted_units group
1    1.Continuing                       13     0
2    1.Continuing                       12     0
3    1.Continuing                       12     0
4    1.Continuing                        9     0
5    1.Continuing                       16     0
6    1.Continuing                       14     0
```

This process produces an **analysis-ready dataset** for the full cohort, including all background covariates and a `group` indicator: **1 = treated** (students who took the 1-unit summer course) and **0 = comparison**.

### Data Preparation

The final data-processing step ensures clean, defensible analysis by:

-   Create a new variable, `initial_standing`, from the logic
-   **Setting intended references** so models build contrasts from the correct baseline (e.g., `fresh` → `sopho` → `junior` → `senior`).
-   **Standardizing categories** to make results comparable and interpretable across tables, plots, and terms.
-   **Normalizing strings** (trim leading/trailing spaces, collapse padding, harmonize case) to prevent duplicate levels and accidental `NA`s.

``` r
library(tidyr)
library(dplyr)
library(readr) # parse_number

data <- final_data

# A new column, initial_standing (standardized) from high school or transfer GPAs
# helper: safe numeric parser
to_num <- function(x) {
  if (is.numeric(x)) return(x)
  x_chr <- trimws(as.character(x))
  dec_is_comma <- grepl(",", x_chr) & !grepl("\\.", x_chr)
  x_std <- ifelse(dec_is_comma, gsub(",", ".", x_chr, fixed = TRUE), x_chr)
  suppressWarnings(readr::parse_number(x_std, locale = readr::locale(decimal_mark = ".")))
}

# clean to numeric (without transformation)
data <- data %>%
  mutate(
    hs_gpa_num = to_num(hs_gpa),
    tr_gpa_num = to_num(transfer_gpa)
  )

# descriptive summaries
summary_stats <- function(x) {
  c(
    n      = length(x),
    n_miss = sum(is.na(x)),
    n_zero = sum(x == 0, na.rm = TRUE),
    mean   = mean(x, na.rm = TRUE),
    min    = min(x, na.rm = TRUE),
    q25    = quantile(x, 0.25, na.rm = TRUE),
    median = median(x, na.rm = TRUE),
    q75    = quantile(x, 0.75, na.rm = TRUE),
    max    = max(x, na.rm = TRUE)
  )
}

rbind(
  hs_gpa      = summary_stats(data$hs_gpa_num),
  transfer_gpa= summary_stats(data$tr_gpa_num)
)
```

```         
                n n_miss n_zero     mean min q25.25% median q75.75% max
hs_gpa       4656      0   1573 220.6108   0       0    297     353 500
transfer_gpa 4656   1971      0 316.6622  57     280    320     360 400
```

The descriptive summary of high school and transfer GPAs highlights important differences in scale and reporting patterns. High school GPAs range from 0 to 500 (mean ≈ 221), consistent with the ERS convention of reporting values on a 0–5.00 scale multiplied by 100. Transfer GPAs, on the other hand, range from 57 to 400 (mean ≈ 317), reflecting a maximum of 4.00 in most transfer institutions. This discrepancy underscores the need to standardize values **within their original GPA source** (high school or transfer) before combining them into a single variable, `initial_standing`.

Additionally, 1,573 high school GPA values are coded as zeros. These correspond primarily to transfer students who did not provide a high school GPA at the time of application. In analytic processing, such zeros should not be treated as true GPAs but instead recoded as missing (`NA` in R). Properly handling these differences—source-specific scales and missing values—is essential to ensure comparability and validity in the propensity score matching (PSM) and subsequent modeling.

``` r
# Clean: zero as NA and standardize within source -> initial_standing selection
data <- data %>%
  mutate(
    # normalize cohort label
    admit_cohort    = trimws(as.character(admit_cohort)),
    admit_cohort_lc = tolower(admit_cohort),
    
    # keep raw copies (optional but helpful)
    hs_gpa_raw       = hs_gpa,
    transfer_gpa_raw = transfer_gpa,
    
    # parse to numeric, keep scale as-is, convert exact 0 -> NA
    hs_gpa_clean       = na_if(to_num(hs_gpa_raw), 0),
    transfer_gpa_clean = na_if(to_num(transfer_gpa_raw), 0)
  ) %>%
  # standardize **within source** (across all rows with non-missing)
  mutate(
    hs_mu = mean(hs_gpa_clean, na.rm = TRUE),
    hs_sd = sd(hs_gpa_clean, na.rm = TRUE),
    tr_mu = mean(transfer_gpa_clean, na.rm = TRUE),
    tr_sd = sd(transfer_gpa_clean, na.rm = TRUE),
    
    hs_gpa_z = ifelse(!is.na(hs_gpa_clean) & hs_sd > 0, (hs_gpa_clean - hs_mu)/hs_sd, NA_real_),
    transfer_gpa_z = ifelse(!is.na(transfer_gpa_clean) & tr_sd > 0, (transfer_gpa_clean - tr_mu)/tr_sd, NA_real_),
    
    # remember which source feeds initial_standing
    initial_source = case_when(
      grepl("^\\s*1\\.\\s*ftf$|\\bftf\\b", admit_cohort_lc)                               ~ "HS",
      grepl("^\\s*2\\.\\s*ugt$|\\bugt\\b", admit_cohort_lc) & !is.na(transfer_gpa_clean)  ~ "Transfer",
      grepl("^\\s*2\\.\\s*ugt$|\\bugt\\b", admit_cohort_lc) &  is.na(transfer_gpa_clean)  ~ "HS",
      TRUE ~ NA_character_
    ),
    
    # standardized initial standing for modeling (z from the source actually used)
    initial_standing_z = case_when(
      initial_source == "HS"       ~ hs_gpa_z,
      initial_source == "Transfer" ~ transfer_gpa_z,
      TRUE                         ~ NA_real_
    ),
    
    # keep a non-standardized initial_standing too, using cleaned source values
    initial_standing = case_when(
      initial_source == "HS"       ~ hs_gpa_clean,
      initial_source == "Transfer" ~ transfer_gpa_clean,
      TRUE                         ~ NA_real_
    )
  ) %>%
  # drop helpers we don't need beyond this point
  select(-admit_cohort_lc, -hs_mu, -hs_sd, -tr_mu, -tr_sd)

# Quick validations

# No zeros remain (they should be NA instead)
assert_true(sum(data$hs_gpa_clean == 0, na.rm = TRUE) == 0, "Zeros remain in hs_gpa (expected NA).")
assert_true(sum(data$transfer_gpa_clean == 0, na.rm = TRUE) == 0, "Zeros remain in transfer_gpa (expected NA).")

# Logic checks for initial_standing
ftf_idx <- grepl("\\bftf\\b", tolower(data$admit_cohort))
ugt_idx <- grepl("\\bugt\\b", tolower(data$admit_cohort))

# FTF rows: initial_standing == hs_gpa (or both NA)
assert_true(
  all((data$initial_standing[ftf_idx] %in% data$hs_gpa_clean[ftf_idx]) |
        (is.na(data$initial_standing[ftf_idx]) & is.na(data$hs_gpa_clean[ftf_idx]))),
  "For FTF, initial_standing should equal hs_gpa (or both NA)."
)

# UGT rows: initial_standing == coalesce(transfer_gpa, hs_gpa)
expected_ugt <- dplyr::coalesce(data$transfer_gpa_clean[ugt_idx], data$hs_gpa_clean[ugt_idx])
assert_true(
  all((data$initial_standing[ugt_idx] %in% expected_ugt) |
        (is.na(data$initial_standing[ugt_idx]) & is.na(expected_ugt))),
  "For UGT, initial_standing should equal transfer_gpa (or hs_gpa if transfer_gpa is NA)."
)

# Within-source z means/sds
data %>%
  summarise(
    hs_mean_z = mean(hs_gpa_z, na.rm = TRUE), hs_sd_z = sd(hs_gpa_z, na.rm = TRUE),
    tr_mean_z = mean(transfer_gpa_z, na.rm = TRUE), tr_sd_z = sd(transfer_gpa_z, na.rm = TRUE)
  )

# Consistency: initial_standing_z equals the chosen source z
stopifnot(all.equal(
  with(subset(data, initial_source == "HS"),       initial_standing_z),
  with(subset(data, initial_source == "HS"),       hs_gpa_z),
  check.attributes = FALSE
))
stopifnot(all.equal(
  with(subset(data, initial_source == "Transfer"), initial_standing_z),
  with(subset(data, initial_source == "Transfer"), transfer_gpa_z),
  check.attributes = FALSE
))
```

```         
No error message was returned. 
```

The `initial_standing` variable was constructed according to the planned logic, and its standardized form (`initial_standing_z`) will be used in the modeling phase. The next step is to define and set the categorical factors.

``` r

# Variables to audit/transform
vars_cat <- c(
  "admit_cohort","enroll_load","student_level","sex","age_band",
  "math_placement_level","writing_placement_level","eop_status",
  "race_ethnicity","pell_eligible","parent_education","residency_status"
)

vars_num <- c("hs_gpa", "transfer_gpa", "initial_standing")

# One place to define canonical factor levels
factor_spec <- list(
  admit_cohort = c("1.FTF","2.UGT"),
  enroll_load = c("Full-time","Part-time"),
  student_level = c("fresh","sopho","junior","senior"),
  sex = c("F","M","N"),
  age_band = c("24_under","25_34","35_over"),
  math_placement_level = c("unneeded","required","recommended"),
  writing_placement_level = c("unneeded","required","recommended"),
  eop_status = c("N","Y"),
  race_ethnicity = c("Black","Asian","Ltnx","White","International","Other"),
  pell_eligible = c("Not Eligible","Pell Eligible"),
  parent_education = c("College Experience","Unknown","First Generation"),
  residency_status = c("Bay","Other_CA","Out_USA","Out_CA")
)

normalize_chr <- function(x) stringr::str_squish(stringr::str_trim(as.character(x)))

freq_tbl <- function(df, var, stage){
  if (!var %in% names(df)) return(NULL)
  tibble(variable = var, level = normalize_chr(df[[var]])) |>
    count(variable, level, name = "n") |>
    group_by(variable) |>
    mutate(pct = n/sum(n)) |>
    ungroup() |>
    mutate(stage = stage)
}

# 1) BEFORE table (frequencies)
data_before <- data
freq_before <- purrr::map_dfr(vars_cat, ~freq_tbl(data_before, .x, "before"))

# Column-by-column transformation THEN factorization

# Minimal recodes & surgical clean-ups if values drifted
data <- data %>%
  mutate(
    admit_cohort = normalize_chr(admit_cohort),
    enroll_load = normalize_chr(enroll_load),
    student_level = case_when(
      # allow numeric 1-4 to map to labels
      suppressWarnings(!is.na(as.integer(student_level))) 
      ~ factor(as.integer(student_level), 
               levels = 1:4, labels = c("fresh","sopho","junior","senior")) |> as.character(),
      TRUE ~ normalize_chr(student_level)
    ),
    sex = normalize_chr(sex),
    age_band = case_when(
      normalize_chr(age_band) %in% c("17 under","18-24") ~ "24_under",
      normalize_chr(age_band) %in% c("25-29","30-34") ~ "25_34",
      normalize_chr(age_band) %in% c("35-59","60 over") ~ "35_over",
      TRUE ~ normalize_chr(age_band)
    ),
    math_placement_level = case_when(
      normalize_chr(math_placement_level) %in% c("I","II","") ~ "unneeded",
      normalize_chr(math_placement_level) == "III" ~ "recommended",
      normalize_chr(math_placement_level) == "IV" ~ "required",
      TRUE ~ normalize_chr(math_placement_level)
    ),
    writing_placement_level = case_when(
      normalize_chr(writing_placement_level) %in% c("I","II","") ~ "unneeded",
      normalize_chr(writing_placement_level) == "III" ~ "recommended",
      normalize_chr(writing_placement_level) == "IV" ~ "required",
      TRUE ~ normalize_chr(writing_placement_level)
    ),
    eop_status = normalize_chr(eop_status),
    race_ethnicity = case_when(
      normalize_chr(race_ethnicity) == "2Black" ~ "Black",
      normalize_chr(race_ethnicity) == "3Asian" ~ "Asian",
      normalize_chr(race_ethnicity) == "6Ltnx" ~ "Ltnx",
      normalize_chr(race_ethnicity) == "7White" ~ "White",
      normalize_chr(race_ethnicity) == "8Intl" ~ "International",
      normalize_chr(race_ethnicity) %in% c("9Unknown", "8TwoMore", "5PacIsl", "1AmInd") ~ "Other", 
      TRUE ~ normalize_chr(race_ethnicity)
    ),
    pell_eligible = case_when(
      str_detect(normalize_chr(pell_eligible), "Not") ~ "Not Eligible",
      str_detect(normalize_chr(pell_eligible), "Pell") ~ "Pell Eligible",
      TRUE ~ normalize_chr(pell_eligible)
    ),
    parent_education = case_when(
      str_starts(normalize_chr(parent_education), "CollegeExperience") ~ "College Experience",
      str_starts(normalize_chr(parent_education), "First") ~ "First Generation",
      str_starts(normalize_chr(parent_education), "Unknown") ~ "Unknown",
      TRUE ~ normalize_chr(parent_education)
    ),
    residency_status = case_when(
      str_detect(normalize_chr(residency_status), "Bay") ~ "Bay",
      str_detect(normalize_chr(residency_status), "Northern|Central|Southern|San Diego") ~ "Other_CA",
      str_detect(normalize_chr(residency_status), "International") ~ "Out_USA",
      str_detect(normalize_chr(residency_status), "outside of CA|Out of CA|Out_CA") ~ "Out_CA",
      TRUE ~ normalize_chr(residency_status)
    ),
hs_gpa = suppressWarnings(as.numeric(hs_gpa)),
transfer_gpa = suppressWarnings(as.numeric(transfer_gpa)), 
initial_standing = suppressWarnings(as.numeric(initial_standing))
)

# Now factorize against the canonical level sets
for (nm in names(factor_spec)) {
  if (nm %in% names(data)) data[[nm]] <- factor(data[[nm]], levels = factor_spec[[nm]])
}

# 3) AFTER table (frequencies)
freq_after <- purrr::map_dfr(vars_cat, ~freq_tbl(data, .x, "after"))

freq_compare <- bind_rows(freq_before, freq_after) %>%
  tidyr::pivot_wider(names_from = stage, values_from = c(n, pct), values_fill = 0) %>%
  arrange(variable, desc(n_after))

# Display
if (requireNamespace("gt", quietly = TRUE)) {
  freq_compare %>%
    group_by(variable) %>%
    arrange(variable, desc(n_after)) %>%
    gt::gt(rowname_col = "level", groupname_col = "variable") %>%
    gt::fmt_percent(dplyr::all_of(c("pct_before","pct_after")), decimals = 1)
} else {
  freq_compare
}

write.csv(data, "psm_final_recoded.csv", row.names = FALSE)
```

Using the **before–after frequency table**, we can quickly validate the transformation and catch any unexpected level changes or data loss. A portion of the R Viewer output is shown in the screenshot below.

![](data%20processing%20screenshot.png){width="372"}

``` r
# Check all categorical vars at once
vars_cat <- c("admit_cohort","enroll_load","student_level","sex","age_band",
              "math_placement_level","writing_placement_level","eop_status",
              "race_ethnicity","pell_eligible","parent_education","residency_status")
lapply(vars_cat, function(v) setNames(list(levels(data[[v]])), v))
```

```         
[[1]]
[[1]]$admit_cohort
[1] "1.FTF" "2.UGT"

[[2]]
[[2]]$enroll_load
[1] "Full-time" "Part-time"

[[3]]
[[3]]$student_level
[1] "fresh"  "sopho"  "junior" "senior"

[[4]]
[[4]]$sex
[1] "F" "M" "N"

[[5]]
[[5]]$age_band
[1] "24_under" "25_34"    "35_over" 

[[6]]
[[6]]$math_placement_level
[1] "unneeded"    "required"    "recommended"

[[7]]
[[7]]$writing_placement_level
[1] "unneeded"    "required"    "recommended"

[[8]]
[[8]]$eop_status
[1] "N" "Y"

[[9]]
[[9]]$race_ethnicity
[1] "Black"         "Asian"         "Ltnx"          "White"         "International" "Other"        

[[10]]
[[10]]$pell_eligible
[1] "Not Eligible"  "Pell Eligible"

[[11]]
[[11]]$parent_education
[1] "College Experience" "Unknown"            "First Generation"  

[[12]]
[[12]]$residency_status
[1] "Bay"      "Other_CA" "Out_USA"  "Out_CA"  
```

------------------------------------------------------------------------

## 4. Propensity Score Matching

The matching analysis follows four steps:

1.  Check initial imbalance.
2.  Implement matching.
3.  Assess the quality of matching.
4.  Determine evaluative analysis sample and method.

### 4.1 Check initial imbalance

**Goal:** quantify pre-treatment differences to justify matching and choose covariates.

-   Inspect summary tables and standardized mean differences (SMDs).
-   Look for overlap/positivity (treated units have comparable controls).

``` r
library(tableone)
psm_summer <- data
head(psm_summer)
```

```         
student_id admit_cohort enroll_load student_level sex gender_identity age_band math_placement_level
1  900455899        2.UGT   Part-time        junior   F              11  35_over             unneeded
2  901027041        2.UGT   Full-time        junior   M              10  35_over             unneeded
3  904393833        2.UGT   Full-time        junior   M              10  35_over             unneeded
4  908471400        2.UGT   Full-time        junior   M              16  35_over             unneeded
5  909419984        2.UGT   Full-time        junior   M              10    25_34             unneeded
6  909960628        2.UGT   Part-time        senior   F              11    25_34             unneeded
  writing_placement_level eop_status race_ethnicity pell_eligible   parent_education residency_status hs_gpa transfer_gpa
1                unneeded          N          White  Not Eligible College Experience              Bay      0          221
2                unneeded          N          Black Pell Eligible College Experience              Bay    258          307
3                unneeded          N          Asian Pell Eligible            Unknown              Bay      0          280
4                unneeded          N          Other Pell Eligible College Experience              Bay      0          346
5                unneeded          N          Other Pell Eligible College Experience              Bay      0          320
6                unneeded          Y           Ltnx Pell Eligible   First Generation              Bay      0          341
  spring25_term_code spring25_status spring25_attempted_units group hs_gpa_num tr_gpa_num hs_gpa_raw transfer_gpa_raw
1              20252    1.Continuing                       13     0          0        221          0              221
2              20252    1.Continuing                       12     0        258        307        258              307
3              20252    1.Continuing                       12     0          0        280          0              280
4              20252    1.Continuing                        9     0          0        346          0              346
5              20252    1.Continuing                       16     0          0        320          0              320
6              20252    1.Continuing                       14     0          0        341          0              341
  hs_gpa_clean transfer_gpa_clean  hs_gpa_z transfer_gpa_z initial_source initial_standing_z 
1           NA                221        NA     -1.7520000       Transfer         -1.7520000              
2          258                307 -1.492095     -0.1769578       Transfer         -0.1769578              
3           NA                280        NA     -0.6714478       Transfer         -0.6714478              
4           NA                346        NA      0.5373056       Transfer          0.5373056              
5           NA                320        NA      0.0611300       Transfer          0.0611300              
6           NA                341        NA      0.4457333       Transfer          0.4457333       

initial_standing
221
307
280
346
320
341
```

Now, we can see data entries based on our canonical definition and level of factors.

**`CreateTableOne(...)`** computes group-wise summaries and **standardized mean differences (SMDs)** on the *raw, unmatched* data split by `group`. Our target is SMDs \< 0.1 (rule of thumb), "well balanced."

``` r
#--- check initial imbalance
balance_vars <- c(
  "admit_cohort", "enroll_load", "student_level", "sex","age_band",
  "math_placement_level","writing_placement_level", 
  "eop_status","race_ethnicity","pell_eligible",
  "parent_education","residency_status","initial_standing", "initial_standing_z"
)

# Pre-matching balance

summer_initial <- CreateTableOne(vars = balance_vars, strata = "group",
                                 data = psm_summer, test = FALSE)
print(summer_initial, smd = TRUE)
```

```         
                                    Stratified by group
                                    0              1              SMD   
  n                                   4436            220               
  admit_cohort = 2.UGT (%)            2233 (50.3)      83 (37.7)   0.256
  enroll_load = Part-time (%)          473 (10.7)      15 ( 6.8)   0.136
  student_level (%)                                                0.219
     fresh                            2171 (48.9)     130 (59.1)        
     junior                           1854 (41.8)      71 (32.3)        
     senior                             44 ( 1.0)       1 ( 0.5)        
     sopho                             367 ( 8.3)      18 ( 8.2)        
  sex (%)                                                          0.086
     F                                2357 (53.1)     126 (57.3)        
     M                                2050 (46.2)      93 (42.3)        
     N                                  29 ( 0.7)       1 ( 0.5)        
  age_band (%)                                                     0.214
     24_under                         3770 (85.0)     201 (91.4)        
     25_34                             497 (11.2)      12 ( 5.5)        
     35_over                           169 ( 3.8)       7 ( 3.2)        
  math_placement_level (%)                                         0.102
     recommended                       433 ( 9.8)      23 (10.5)        
     required                          689 (15.5)      42 (19.1)        
     unneeded                         3314 (74.7)     155 (70.5)        
  writing_placement_level (%)                                      0.028
     recommended                        54 ( 1.2)       3 ( 1.4)        
     required                          451 (10.2)      24 (10.9)        
     unneeded                         3931 (88.6)     193 (87.7)        
  eop_status = Y (%)                   695 (15.7)      28 (12.7)   0.084
  race_ethnicity (%)                                               0.204
     Asian                             939 (21.2)      35 (15.9)        
     Black                             294 ( 6.6)      14 ( 6.4)        
     International                     249 ( 5.6)      10 ( 4.5)        
     Ltnx                             1772 (39.9)      86 (39.1)        
     Other                             505 (11.4)      27 (12.3)        
     White                             677 (15.3)      48 (21.8)        
  pell_eligible = Pell Eligible (%)   2247 (50.7)      89 (40.5)   0.206
  parent_education (%)                                             0.269
     College Experience               2627 (59.2)     158 (71.8)        
     First Generation                 1577 (35.6)      53 (24.1)        
     Unknown                           232 ( 5.2)       9 ( 4.1)        
  residency_status (%)                                             0.563
     Bay                              2982 (67.2)      90 (40.9)        
     Other_CA                         1217 (27.4)     116 (52.7)        
     Out_CA                             71 ( 1.6)       6 ( 2.7)        
     Out_USA                           166 ( 3.7)       8 ( 3.6)        
  initial_standing (mean (SD))      324.19 (50.08) 333.37 (47.76)  0.188
```

-   **Large / structural imbalance:** `residency_status` **0.563** (very big)

-   **Moderate imbalance:** `admit_cohort` **0.256**, `student_level` **0.219**, `race_ethnicity` **0.204**, `pell_eligible` **0.206**, `parent_education` **0.269**, `age_band` **0.214**

-   **Small / borderline:** `enroll_load` **0.136**, `math_placement_level` **0.102**

-   **Well balanced already:** `writing_placement_level` **0.028**, `sex` **0.086**, `eop_status` **0.084**

-   **Continuous check:** `initial_standing` **0.188** (borderline) and `initial_standing_z` **0.148** (improved but still borderline)

#### Matching setup

Covariates in the **propensity model**: `admit_cohort + enroll_load + student_level + sex + age_band + math_placement_level + writing_placement_level + eop_status + race_ethnicity + pell_eligible + parent_education + residency_status`

**Exact matching (design / structural locks)**

-   We **exact-match** on: `admit_cohort,` `enroll_load,` `student_level`, `sex.`

-   This forces treated and control units to be compared **within the same strata** for these key variables; within each stratum, the nearest neighbor on the propensity score is chosen.

-   <div>

    **Why this matters**

    -   The **propensity score (PS)** summarizes the likelihood of treatment given all covariates.

    -   **Near-equal PS** implies similar overall confounding risk, but pairs can still differ on an influential covariate.

    -   Exact matching prevents this by **locking** matches within identical profiles for the most important design factors.

    **Other guardrails (beyond the scope of this workshop)**

    -   **Caliper**: set a maximum allowed PS distance; if no control is close enough, the treated unit is left unmatched. This reduces bad matches (poor overlap) at the cost of a smaller sample.

    -   **Mahalanobis within a PS caliper**: keep pairs close on PS **and** close on specific covariates (e.g., GPA).

    -   **Richer PS models**: add nonlinearity (e.g., splines for GPA) and interactions (e.g., `pell_eligible:race_ethnicity`) so PS similarity better reflects the assignment mechanism.

    </div>

Excluding **`initial_standing_z` from the PS** and addressing differences in it **in the final model**.

-   **Derived & non-linear**: `initial_standing` combines HS and transfer GPAs, which often show skew, ceilings/floors, and nonlinearity. Forcing it into a simple logit PS risks misspecification and distorted overlap.
-   **Design-first matching**: We prioritize balancing **background/design covariates** (cohort, load, level, sex, etc.). This creates pairs comparable on structural features; then we **assess** whether `initial_standing_z` differs post-match.
-   **Clear inference & pragmatism**: It’s more intuitive to (1) match on background, (2) **test** differences in `initial_standing_z`, and (3) **adjust** for it in the final model (ANCOVA/conditional logit) if needed—yielding transparent, defensible reporting.
-   **Optional tightening without PS burden**: If desired, we can **tighten locally** on `initial_standing_z` via **Mahalanobis within a PS caliper**, guarding against functional-form issues while preserving overlap.

> #### Workflow without Additional Guardrails
>
> 1.  Apply **Exact matching** on the design factors above.
> 2.  **Validate post-match balance** (e.g., SMDs \< 0.10 where feasible).
> 3.  If residual imbalance persists, **choose the appropriate final analysis** (e.g., include covariates in the outcome model or consider alternative matching refinements).

### 4-2. Implement matching.

We use **1:1 nearest-neighbor matching without replacement** so each treated unit forms a unique pair with a control. This produces a clean matched dataset for **paired** analyses (e.g., McNemar, conditional logistic regression).

``` r
library(MatchIt)

ps_formula <- group ~ admit_cohort + enroll_load + student_level + sex +
  age_band + math_placement_level + writing_placement_level +
  eop_status + race_ethnicity + pell_eligible + parent_education +
  residency_status

set.seed(20250930)  # reproducibility

matching <- matchit(
  formula  = ps_formula,
  data     = psm_summer,
  method   = "nearest",
  distance = "logit",   # default
  ratio    = 1,
  exact    = ~ admit_cohort + enroll_load + student_level + sex
  # replace = FALSE   # for paired comparison; default; omitted for simplicity
  # , estimand = "ATT" # default is ATT; include if you want to be explicit
)

matched_data <- match.data(matching)
```

### 4.3. Assess the quality of matching.

#### Global Check

``` r
summary(matching, un = FALSE)
```

-   The table below lists one row per covariate (or per **level** for multi-category factors) and reports these **diagnostics**:

    -   **Means Treated / Means Control**\
        These columns report the average value of each covariate in the matched treatment and control samples.
        -   For binary indicator (0/1) variables, the means represent proportions. For example, a mean of **0.6227** for *admit_cohort1.FTF* indicates that **62.3%** of students are FTF in both groups.
        -   For variables balanced through PS-based matching, such as *race_ethnicityAsian*, the means may differ slightly. For instance, values of 0.159 (treated) and 0.177 (control) show that **15.9%** of the treated group and **17.7%** of the matched control group are Black. This is a close alignment, especially considering that the pre-matching proportions were **21.2%** in the tutoring group and **15.9%** in the broader matching pool.
        -   For continuous covariates, the values reflect arithmetic means.
    -   **Std. Mean Diff. (SMD)**\
        Difference in group means divided by a pooled SD. Unit-free measure of imbalance.
        -   **Rule of thumb:** \|SMD\| \< **0.10** is *well balanced*; 0.10–0.15 is usually acceptable in practice.
        -   Advantage: not affected by sample size (unlike p-values).
    -   **Var. Ratio**\
        Ratio of the control variance to the treated variance for continuous variables.
        -   Target ≈ **1.0**; values between **0.8 and 1.25** are often considered acceptable.
        -   Not shown (or “.”) for indicator variables.
    -   **eCDF Mean / eCDF Max**\
        Differences between the empirical CDFs of treated vs control for a variable.
        -   **eCDF Mean:** average absolute difference across the variable’s support.
        -   **eCDF Max:** largest absolute difference (a Kolmogorov-Smirnov–style metric).
        -   Smaller is better; use these to catch imbalances beyond the mean (e.g., tail issues).
    -   **Std. Pair Dist.** *(post-match only)*\
        Average (standardized) distance between matched pairs on this covariate.
        -   Smaller implies tighter pairing on that variable.
        -   Useful for spotting variables where pairs are still relatively far apart even if SMD is small.

    **How to interpret results**

    -   **Multi-level factors** (e.g., `race_ethnicity`) appear as separate indicator rows such as `race_ethnicityWhite`, `race_ethnicityAsian,` etc.

    -   Review **SMDs across all levels**—a single large \|SMD\| indicates imbalance for that level.

        -   **Primary target**: aim for **\|SMD\| \< 0.10** for each row (strive for \< 0.05 when feasible).

        -   **Exact-matched variables** should show **identical means** and **SMD = 0** (by construction).

    -   **Variance ratios** (*continuous variables only*): target **0.8–1.25**. It’s normal for **Var. Ratio** to be blank for binary indicators.

    -   **Distance** row summarizes the propensity score scale; after matching, **SMD ≈ 0** indicates treated and control have similar PS distributions.

    -   **eCDF Max / eCDF Mean**: smaller is better; they’re secondary checks for shape differences when SMD looks fine.

    -   In this PSM, covariates are **binary**, so **eCDF Max** and **eCDF Mean** both equal **the absolute difference in proportions**(\|Means Treated − Means Control\|).

> ***Practical note: with binary contrasts, we can focus on the SMD as the primary diagnostic.***

-   **What to do if a row exceeds the target**

    -   If it’s a rare level (tiny cell), small absolute count differences can inflate SMD; consider collapsing levels (if substantively reasonable) or adjusting for that covariate in the outcome model.
    -   If a continuous covariate shows poor balance (SMD or Var. Ratio), consider adjusting for it flexibly (e.g., spline) in the final model.
    -   Keep the matched design (pairs) intact if your analysis plan uses paired methods (e.g., McNemar, conditional logistic regression with `strata(subclass)`).

> In this workshop, we treat these **diagnostics as checks rather than hard pass/fail gates**: we document residual imbalances and adjust for them in the final analysis (e.g., add covariates to the model or use flexible terms), while preserving the matched pairs for interpretable, practitioner-friendly inference.

```         
Call:
matchit(formula = ps_formula, data = psm_summer, method = "nearest", 
    distance = "logit", exact = c("admit_cohort", "enroll_load", 
        "student_level", "sex"), ratio = 1)

Summary of Balance for Matched Data:
                                   Means Treated Means Control Std. Mean Diff. Var. Ratio
distance                                  0.0717        0.0717          0.0001     1.0008
admit_cohort1.FTF                         0.6227        0.6227          0.0000          .
admit_cohort2.UGT                         0.3773        0.3773          0.0000          .
enroll_loadFull-time                      0.9318        0.9318          0.0000          .
enroll_loadPart-time                      0.0682        0.0682          0.0000          .
student_levelfresh                        0.5909        0.5909          0.0000          .
student_leveljunior                       0.3227        0.3227          0.0000          .
student_levelsenior                       0.0045        0.0045          0.0000          .
student_levelsopho                        0.0818        0.0818          0.0000          .
sexF                                      0.5727        0.5727          0.0000          .
sexM                                      0.4227        0.4227          0.0000          .
sexN                                      0.0045        0.0045          0.0000          .
age_band24_under                          0.9136        0.9182         -0.0162          .
age_band25_34                             0.0545        0.0591         -0.0200          .
age_band35_over                           0.0318        0.0227          0.0518          .
math_placement_levelrecommended           0.1045        0.1091         -0.0149          .
math_placement_levelrequired              0.1909        0.1591          0.0810          .
math_placement_levelunneeded              0.7045        0.7318         -0.0598          .
writing_placement_levelrecommended        0.0136        0.0000          0.1176          .
writing_placement_levelrequired           0.1091        0.1000          0.0292          .
writing_placement_levelunneeded           0.8773        0.9000         -0.0693          .
eop_statusN                               0.8727        0.8727          0.0000          .
eop_statusY                               0.1273        0.1273          0.0000          .
race_ethnicityAsian                       0.1591        0.1773         -0.0497          .
race_ethnicityBlack                       0.0636        0.0455          0.0745          .
race_ethnicityInternational               0.0455        0.0273          0.0873          .
race_ethnicityLtnx                        0.3909        0.4136         -0.0466          .
race_ethnicityOther                       0.1227        0.1091          0.0416          .
race_ethnicityWhite                       0.2182        0.2273         -0.0220          .
pell_eligibleNot Eligible                 0.5955        0.6000         -0.0093          .
pell_eligiblePell Eligible                0.4045        0.4000          0.0093          .
parent_educationCollege Experience        0.7182        0.7273         -0.0202          .
parent_educationFirst Generation          0.2409        0.2455         -0.0106          .
parent_educationUnknown                   0.0409        0.0273          0.0688          .
residency_statusBay                       0.4091        0.4091          0.0000          .
residency_statusOther_CA                  0.5273        0.5318         -0.0091          .
residency_statusOut_CA                    0.0273        0.0318         -0.0279          .
residency_statusOut_USA                   0.0364        0.0273          0.0486          .
                                   eCDF Mean eCDF Max Std. Pair Dist.
distance                              0.0006   0.0091          0.0017
admit_cohort1.FTF                     0.0000   0.0000          0.0000
admit_cohort2.UGT                     0.0000   0.0000          0.0000
enroll_loadFull-time                  0.0000   0.0000          0.0000
enroll_loadPart-time                  0.0000   0.0000          0.0000
student_levelfresh                    0.0000   0.0000          0.0000
student_leveljunior                   0.0000   0.0000          0.0000
student_levelsenior                   0.0000   0.0000          0.0000
student_levelsopho                    0.0000   0.0000          0.0000
sexF                                  0.0000   0.0000          0.0000
sexM                                  0.0000   0.0000          0.0000
sexN                                  0.0000   0.0000          0.0000
age_band24_under                      0.0045   0.0045          0.0809
age_band25_34                         0.0045   0.0045          0.1001
age_band35_over                       0.0091   0.0091          0.2072
math_placement_levelrecommended       0.0045   0.0045          0.0446
math_placement_levelrequired          0.0318   0.0318          0.1041
math_placement_levelunneeded          0.0273   0.0273          0.0797
writing_placement_levelrecommended    0.0136   0.0136          0.1176
writing_placement_levelrequired       0.0091   0.0091          0.1458
writing_placement_levelunneeded       0.0227   0.0227          0.1524
eop_statusN                           0.0000   0.0000          0.0364
eop_statusY                           0.0000   0.0000          0.0364
race_ethnicityAsian                   0.0182   0.0182          0.0994
race_ethnicityBlack                   0.0182   0.0182          0.0745
race_ethnicityInternational           0.0182   0.0182          0.1309
race_ethnicityLtnx                    0.0227   0.0227          0.1397
race_ethnicityOther                   0.0136   0.0136          0.1524
race_ethnicityWhite                   0.0091   0.0091          0.1101
pell_eligibleNot Eligible             0.0045   0.0045          0.1389
pell_eligiblePell Eligible            0.0045   0.0045          0.1389
parent_educationCollege Experience    0.0091   0.0091          0.1212
parent_educationFirst Generation      0.0045   0.0045          0.1169
parent_educationUnknown               0.0136   0.0136          0.1147
residency_statusBay                   0.0000   0.0000          0.0364
residency_statusOther_CA              0.0045   0.0045          0.0819
residency_statusOut_CA                0.0045   0.0045          0.0837
residency_statusOut_USA               0.0091   0.0091          0.0971

Sample Sizes:
          Control Treated
All          4436     220
Matched       220     220
Unmatched    4216       0
Discarded       0       0
```

-   **Pre → Post:** almost everything collapsed to \~0 SMD (great!!)

-   The only one nudging past the 0.10 heuristic is `writing_placement_level = recommended` at **0.118**. Others are ≤ \~0.09: `writing_placement_level = recommended` is a **rare category** (tiny counts). With small cells, SMDs can look a bit jumpy even when absolute differences are small.

-   **Sample sizes:** 220 treated, 220 controls (no treated dropped).

-   **Exact-match fields** (`admit_cohort`, `enroll_load`, `student_level`, `sex`) are perfectly aligned, as expected (SMD = 0, eCDF deltas = 0).

#### Check for Initial Standing (High School or Transferred GPA)

When examining differences in initial academic standing between treated students and their matched counterparts, two key variables are used:

-   **`group`**: Created during data processing; coded as 1 for students in the treated group (those who took the course) and 0 for students in the control group.
-   **`subclass`**: Generated automatically during the propensity score matching procedure; it identifies the matched pairs (or subclasses) of students.

***1) Balance metric***

``` r
vars <- c("initial_standing_z")
post_bal <- CreateTableOne(vars = vars, strata = "group",
                           data = as.data.frame(matched_data), test = FALSE)
print(post_bal, smd = TRUE)
```

```         
                               S Stratified by group
                                   0           1           SMD   
  n                               220         220              
  initial_standing_z (mean (SD)) 0.10 (0.94) 0.12 (0.91)  0.025
```

> SMD for the initial standing is 0.025, well below 0.10 (Good balance!!)

``` r
# simple variance ratio check (because it is numeric)
vr <- matched_data %>%
  filter(!is.na(initial_standing_z)) %>%
  summarise(
    var_t = var(initial_standing_z[group == 1]),
    var_c = var(initial_standing_z[group == 0]),
    var_ratio = var_t / var_c
  )
print(vr) # Rule of thumb: Ratios between 0.8 and 1.25 are usually acceptable.
```

```         
    var_t     var_c    var_ratio
1 0.8250381 0.8924194  0.924496
```

> That’s very close to 1.0 (≈0.92), which indicates the treated and control groups have nearly the same variability in `initial_standing_z` after matching.

***2) Paired tests on within-pair differences***

-   To evaluate differences in initial academic standing within matched pairs, we explicitly created a new variable, **`diffs`**, representing the pairwise difference (*treated − control*). This allows us to test whether the median difference (Wilcoxon signed-rank test) or the mean difference (paired t-test) is statistically equal to zero.
-   A **histogram of `diffs`** provides a quick view of the distribution of these differences, while a **QQ plot (`qqnorm(diffs); qqline(diffs)`)** is the standard diagnostic for assessing approximate normality. The normality check is relevant only for the paired t-test, since the Wilcoxon signed-rank test does not require this assumption.
-   For completeness, we implemented both approaches: the Wilcoxon test as the more robust method, and the paired t-test as a sensitivity check.

``` r
# Keep only subclasses with exactly 2 members and non-missing values
paired_is <- matched_data %>%
  filter(!is.na(initial_standing_z)) %>%
  group_by(subclass) %>%
  filter(n() == 2) %>%
  ungroup() %>%
  mutate(trt_label = ifelse(group == 1, "treated", "control")) %>%
  select(subclass, trt_label, initial_standing_z) %>%
  pivot_wider(names_from = trt_label, values_from = initial_standing_z) %>%
  tidyr::drop_na(treated, control)

# Differences (treated − control)
diffs <- paired_is$treated - paired_is$control

# Quick glance & tests
summary(diffs)
hist(diffs, breaks = 30)
qqline(diffs)
wilcox.test(diffs, mu = 0, exact = FALSE)                        # primary (robust)
t.test(paired_is$treated, paired_is$control, paired = TRUE)      # sensitivity
```

![](images/initial standing z histogram.png){fig-align="left" width="301"}

![](images/initial standing z qqline.png){width="321"}

> The plots show that the differences are approximately normal with a small left skew. This means the paired *t*-test is still reasonable, but the Wilcoxon signed-rank test is a good robust alternative that doesn’t rely on normality.

```         
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-3.49806 -0.71519  0.03970  0.01757  0.71519  2.98525 

    
    Wilcoxon signed rank test with continuity correction
data:  diffs
V = 12190, p-value = 0.6954
alternative hypothesis: true location is not equal to 0

Paired t-test
data:  paired_is$treated and paired_is$control
t = 0.23824, df = 218, p-value = 0.8119
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 -0.1278087  0.1629556

sample estimates:
mean difference 
     0.01757344 
```

> -   V = 12,190; p = 0.695 → no within-pair median shift
> -   t = 0.238; df = 218; p = 0.811; mean diff = **+0.02**; 95% CI \[−0.13, 0.16\] → no mean shift.
>
> **Baseline standing balance.** After matching, `initial_standing_z` showed excellent balance (SMD = 0.03). In paired tests using complete pairs (n = 219), the Wilcoxon signed-rank test indicated no median shift and the paired t-test likewise found no mean shift.
>
> We proceed with paired outcome analyses without additional adjustment for `initial_standing_z` for this case (results are unchanged if included as a covariate).

------------------------------------------------------------------------

## 5. Final Modeling to Test Impact of the Course

The outcome variable is the 2nd semester retention (binary) and the group variable divides students into the treated (took the summer course) and the control (matched through the PSM).

One more step of data processing

**After PSM**

| Student ID | Various Columns | group | subclass |
|------------|-----------------|-------|----------|
| 1          |                 | 1     | 1        |
| 2          |                 | 0     | 1        |
| 3          |                 | 1     | 2        |
| 4          |                 | 0     | 2        |
| 5          |                 | 1     | 3        |
| 6          |                 | 0     | 4        |

**Wide Format for Paired Tests**

| subclass | Various Columns | treated SID | matched SID |
|----------|-----------------|-------------|-------------|
| 1        |                 | 1           | 2           |
| 2        |                 | 3           | 4           |
| 3        |                 | 1           | 2           |

``` r
# 1) Ensure outcome is coded binary at the individual level
matched_out <- matched_data %>%
  mutate(
    # if spring25_status is blank/NA, treat as Not_enrolled
    spring25_bin = ifelse(is.na(spring25_status) | spring25_status == "",
                          "Not_enrolled",
                          ifelse(spring25_status %in% c("1.Continuing","enrolled","20252"),
                                 "Continuing", "Not_enrolled")),
    spring25_bin = factor(spring25_bin, levels = c("Not_enrolled","Continuing"))
  )

# 2) Collapse to one row per pair: treated vs control
pairs <- matched_out %>%
  mutate(side = ifelse(group == 1, "treated", "control")) %>%
  select(subclass, side, spring25_bin) %>%
  pivot_wider(names_from = side, values_from = spring25_bin)

# Quick audit of empties we recoded:
table(pairs$treated, useNA="ifany"); table(pairs$control, useNA="ifany")

# 3) 2×2 table of paired outcomes
tab <- table(pairs$treated, pairs$control)
tab
# Rows = treated, Cols = control
#           control
#            Not_enrolled Continuing
# treated
# Not_enrolled      a           c
# Continuing        b           d
```

```         
Not_enrolled   Continuing 
           8          212 

Not_enrolled   Continuing 
           20         200
           
           
               Not_enrolled Continuing
  Not_enrolled            1          7
  Continuing             19        193          
           
```

> There is no missing value in the outcome for both groups. The treated group has the retention rate of 96.4% while the control group 90.9%. (The overall retention rate for the entire sample is 93.2%.)

In addition to reporting the McNemar’s test, it is often useful to provide effect size measures that quantify the magnitude of the difference between treated students and their matched controls. Three complementary metrics are commonly reported:

-   **Overall Risk Difference (O_RD):** This captures the difference in the proportion of *Continuing* outcomes between the treated group and the control group, calculated across all matched pairs. A positive estimate indicates that, overall, treated students have a higher continuation rate than their matched controls.
-   **Discordant-Pairs Risk Difference (D_RD):** This focuses only on the discordant pairs—those where one student continued and the other did not. It represents the net proportion of discordant pairs that favor the treated group.
-   **Matched-Pairs Odds Ratio (OR):** Also known as the McNemar odds ratio, this compares the odds of discordant pairs being of type *b* (treated continues, control does not) versus type *c* (treated does not, control continues). An odds ratio greater than 1 indicates that treatment is associated with a higher likelihood of continuing, conditional on the pairs where outcomes differ.

``` r
# 4) McNemar’s test (use exact when discordant pairs are few)
mcnemar.test(tab, correct = TRUE)     # Yates-corrected chi-square

# Overall Risk Difference (all pairs)
rd_all <- (b - c) / n

# Paired Risk Difference (discordant pairs only)
rd_pairs <- (b - c) / (b + c)

# Odds Ratio (McNemar)
or_hat <- if (c == 0) Inf else if (b == 0) 0 else b / c

# Print with 2 decimal places
cat("Overall RD   =", sprintf("%.2f", rd_all), "\n")
cat("Paired RD    =", sprintf("%.2f", rd_pairs), "\n")
cat("Odds Ratio   =", sprintf("%.2f", or_hat), "\n")
```

```         
McNemar's chi-squared = 5.1429, df = 1, p-value = 0.02334

Overall RD   = 0.05
Paired RD    = 0.46
Odds Ratio   = 2.71
```

> Treated retention was **5.5 percentage points** higher than matched controls, and **within pairs** the **odds of retention** were about **2.7×** higher for students who took the summer course than for their matched controls. This difference was **statistically significant** (*p* \< 0.05). Together, these paired estimators (paired RD and conditional OR) highlight how **propensity score matching (PSM)** can isolate a program’s impact by comparing like with like and removing confounding from background factors.

## 6. Caveats and Moving Forward

Even with careful matching, detected effects can **attenuate or flip** under two common conditions in this design:

-   **Nearest-neighbor instability.** Greedy nearest-neighbor matching can select different controls under ties or limited overlap, yielding different matched samples (and estimates).
-   **Ceiling outcome with few discordants.** Second-semester retention is very high for most students. With few **discordant pairs** (treated=1/control=0 vs treated=0/control=1), **McNemar’s test** has low power; small shifts in pairing can change significance.

To strengthen future evaluations:

-   **Use a more discriminating outcome.** Prefer **one-year retention**, which typically yields more variation and more discordant pairs.
-   **Run simple sensitivities.** Generate an alternative control draw (e.g., a second seed or **1:2 matching**) and show the estimate’s robustness across draws.

``` r
set.seed(1)
m_A <- matchit(ps_formula, data = data, method = "nearest",
               exact = c("admit_cohort","enroll_load","student_level","sex"),
               distance = "logit", ratio = 1, m.order = "largest")
md_A <- match.data(m_A)

set.seed(2)  # different tie-breaking
m_B <- matchit(ps_formula, data = data, method = "nearest",
               exact = c("admit_cohort","enroll_load","student_level","sex"),
               distance = "logit", ratio = 1, m.order = "largest")
md_B <- match.data(m_B)

# Compare McNemar on A vs B
mk_mcnemar <- function(md) {
  pairs <- md %>%
    mutate(y = as.integer(spring25_status %in% c("Continuing","enrolled","20252")),
           side = ifelse(group == 1, "treated", "control")) %>%
    select(subclass, side, y) %>%
    tidyr::pivot_wider(names_from = side, values_from = y) %>%
    filter(!is.na(treated) & !is.na(control))
  tab <- table(factor(pairs$treated, 0:1, c("Not","Cont")),
               factor(pairs$control, 0:1, c("Not","Cont")))
  list(tab = tab, mc = mcnemar.test(tab, correct = FALSE, exact = TRUE))
}
resA <- mk_mcnemar(md_A); resB <- mk_mcnemar(md_B)
resA$mc; resB$mc  # often very similar, but can differ with few discordants
```

``` r
set.seed(20250925)
ps_formula <- group ~ admit_cohort + enroll_load + student_level + sex +
  age_band + math_placement_level + writing_placement_level +
  eop_status + race_ethnicity + pell_eligible + parent_education +
  residency_status

m_12 <- matchit(ps_formula, data = data,
                method = "nearest", ratio = 2,
                exact = c("admit_cohort","enroll_load","student_level","sex"),
                distance = "logit", replace = FALSE)

md_12 <- match.data(m_12)

# binary outcome
md_12 <- md_12 %>%
  mutate(retained = as.integer(spring25_status %in% c("Continuing","enrolled","20252")))

# Matched-set analysis (works for 1:k): conditional logistic regression
library(survival)
fit_12 <- clogit(retained ~ group + strata(subclass), data = md_12)
summary(fit_12)  # report OR and CI
```

-   **Enhance matching stability.** Consider **optimal** or **full** matching (less order-dependent) or specify seeds/order for reproducible nearest-neighbor results.
